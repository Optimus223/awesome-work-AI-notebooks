{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T14:22:16.610471Z",
     "iopub.status.busy": "2021-02-23T14:22:16.610129Z",
     "iopub.status.idle": "2021-02-23T14:22:16.627784Z",
     "shell.execute_reply": "2021-02-23T14:22:16.626866Z",
     "shell.execute_reply.started": "2021-02-23T14:22:16.610384Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-wilson",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# spaCy - SpaCy Build a sentiment analysis model using Twitter\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/spaCy/SpaCy_Build_a_sentiment_analysis_model_using_Twitter.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/open_in_naas.svg\"/></a><br><br><a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=&template=template-request.md&title=Tool+-+Action+of+the+notebook+\">Template request</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=spaCy+-+SpaCy+Build+a+sentiment+analysis+model+using+Twitter:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-programmer",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #twitter #spaCy #data #nlp #sentiment #classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e948d7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Tannia Dubon](https://www.linkedin.com/in/tanniadubon/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook demonstrates how to use spaCy to build a sentiment analysis model using Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-truth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mediterranean",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install required packages as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-surfing",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "%pip install --user requests pandas pyyaml datetime numpy datetime matplotlib wordcloud seaborn spacy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf094d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "import os\nimport requests\nimport pandas as pd\nimport json\nimport ast\nimport yaml\n\nimport numpy as np\nfrom datetime import datetime, date\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport re\nimport seaborn as sns\nimport string\nimport warnings\nimport random\nimport spacy\nfrom spacy.training import Example\nfrom spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL"
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-trustee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Bearer Token to Use Twitter API\n",
    "\n",
    "#### How to get a bearer token ?\n",
    "\n",
    "bearer_token \u2013 the token used for authentication https://developer.twitter.com/en/docs/authentication/oauth-2-0/bearer-tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-melbourne",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "BEARER_TOKEN = \"...\""
  },
  {
   "cell_type": "markdown",
   "id": "6838a83f-52c6-44d2-aac4-d1217b41f095",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Setup Twitter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ea700-a1d4-449d-a6d1-1d078c8d4d1c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# Twitter query to fetch tweets. Learn how to build one here: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\nTWITTER_QUERY = (\n    '(Putin OR Lukashenka OR Russia OR \"Vladimir Putin\") -is:retweet lang:en'\n)\n\n# Number of tweets to fetch (max 100).\nTWITTER_MAX_RESULTS = 100"
  },
  {
   "cell_type": "markdown",
   "id": "registered-showcase",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5dbcac",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Retrieve data from Twitter\n",
    "Enter keywords for query in the create_url() function. \n",
    "See https://tinyurl.com/2j5phrhu for instructions on customizing your query syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7563be",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "def create_url(query, max_results=100):\n    tweet_fields = \"tweet.fields=created_at,public_metrics,context_annotations,text,possibly_sensitive,geo\"\n    url = \"https://api.twitter.com/2/tweets/search/recent?max_results={}&query={}&{}\".format(\n        max_results, query, tweet_fields\n    )\n    return url\n\n\ndef create_headers(bearer_token):\n    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n    return headers\n\n\ndef connect_to_endpoint(url, headers):\n    response = requests.request(\"GET\", url, headers=headers)\n    if response.status_code != 200:\n        raise Exception(response.status_code, response.text)\n    return response.json()"
  },
  {
   "cell_type": "markdown",
   "id": "a9806e9e-dae1-4958-9904-736ed4055db1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Download tweets and store them in a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093019b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "url = create_url(TWITTER_QUERY, TWITTER_MAX_RESULTS)\nbearer_token = BEARER_TOKEN\nheaders = create_headers(bearer_token)\njson_response = connect_to_endpoint(url, headers)\njson_response"
  },
  {
   "cell_type": "markdown",
   "id": "aa44cf5f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Define functions to retrieve each tweet field of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21cf65",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# Initialize Lists\nid_data = []\ndate_data = []\nrtwt_data = []\nreply_data = []\ntext_data = []"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88e4cb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "def get_id():\n    for data in json_response[\"data\"]:\n        id_record = data[\"id\"]\n        id_data.append(id_record)\n\n\ndef get_created_at():\n    for data in json_response[\"data\"]:\n        date_record = data[\"created_at\"]\n        date_data.append(date_record)\n\n\ndef retweet_count():\n    for retweets in json_response[\"data\"]:\n        rtwt_count = retweets[\"public_metrics\"][\"retweet_count\"]\n        rtwt_data.append(rtwt_count)\n\n\ndef reply_count():\n    for reply in json_response[\"data\"]:\n        reply_count = reply[\"public_metrics\"][\"reply_count\"]\n        reply_data.append(reply_count)\n\n\ndef get_text():\n    for data in json_response[\"data\"]:\n        text_record = data[\"text\"]\n        text_data.append(text_record)\n\n\nget_id()\nget_created_at()\nretweet_count()\nreply_count()\nget_text()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a080ba2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "def get_domain():\n    d_id = []\n    d_name = []\n    d_desc = []\n    d_twt_id = []\n\n    for j in json_response[\"data\"]:\n        for i in j:\n            if i == \"context_annotations\":\n                for d in j[\"context_annotations\"]:\n                    d_id.append(d[\"domain\"][\"id\"])\n                    d_name.append(d[\"domain\"][\"name\"])\n                    d_desc.append(d[\"domain\"][\"description\"])\n                    d_twt_id.append(j[\"id\"])\n\n    domain = {\"id\": d_id, \"name\": d_name, \"desc\": d_desc, \"tweet id\": d_twt_id}\n    return domain\n\n\ndef get_entity():\n    e_id = []\n    e_name = []\n    e_desc = []\n    e_twt_id = []\n\n    for j in json_response[\"data\"]:\n        for i in j:\n            if i == \"context_annotations\":\n                for d in j[\"context_annotations\"]:\n                    e_id.append(d[\"entity\"][\"id\"])\n                    e_name.append(d[\"entity\"][\"name\"])\n                    e_twt_id.append(j[\"id\"])\n\n    entity = {\"id\": e_id, \"name\": e_name, \"desc\": e_desc, \"tweet id\": e_twt_id}\n    return entity"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0554a-1704-4f8c-bbd8-9c2a1c620a71",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# inspect output\nprint(get_entity())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a606e5c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "print(get_domain())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a8d7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "print(len(id_data), len(date_data), len(rtwt_data), len(reply_data), len(text_data))"
  },
  {
   "cell_type": "markdown",
   "id": "e016a345",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save data to pandas dataframe and clean and format text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e14bd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# saved tweet fields doe not include entity or domain data\nsave_data = {\n    \"id\": id_data,\n    \"date\": date_data,\n    \"retweet count\": rtwt_data,\n    \"reply count\": reply_data,\n    \"text\": text_data,\n}\ndf = pd.DataFrame(save_data)\ndf.to_csv(\"pol_tweet_data.csv\")\ndf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360510d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "def cleanup_text(file, rem_item):\n    r = re.findall(rem_item, file)\n    for i in r:\n        file = re.sub(i, \"\", file)\n    return file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed206aa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# remove handles\ndf[\"clean text\"] = np.vectorize(cleanup_text)(df[\"text\"], \"@[\\w]*\")\ndf[\"clean text\"].head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd595db",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "len(df[\"clean text\"])\nprint(df[\"clean text\"])"
  },
  {
   "cell_type": "markdown",
   "id": "629ea421",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Tokenize text in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25aa678",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "#convert to tokens\nnlp = None\ntry:\n    nlp = spacy.load(\"en_core_web_lg\") #here you can load a model that you'd previously trained\nexcept:\n    ! python -m spacy download en_core_web_lg\n    nlp = spacy.load(\"en_core_web_lg\")\n    \ntext = str(df[\"clean text\"])\ndoc = nlp(text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74af8c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "tokens_list = []\nfor token in doc:\n    tokens_list.append(token)\n\ntokens_list"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c132a5b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# Review entities recognized\nfor ent in doc.ents:\n    print(ent.text, ent.label_)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aac127",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# Add a category for entities of interest, if needed.\nfrom spacy.matcher import PhraseMatcher\n\nmatcher = PhraseMatcher(nlp.vocab)\n\n# define politicians as entities\nterms = [\"Putin\", \"Zelensky\"]\npatterns = [nlp.make_doc(term) for term in terms]\nmatcher.add(\"politiciansList\", None, *patterns)\n\nmatches = matcher(doc)\n\n# this prints out the spans where the instances are found and the entity identified\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])"
  },
  {
   "cell_type": "markdown",
   "id": "tested-astrology",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-louisville",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "config = {\"threshold\": 0.5, \"model\": DEFAULT_SINGLE_TEXTCAT_MODEL}\n\ntextcat = nlp.add_pipe(\"textcat\", config=config)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48120d6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# create training data for your example consisting of examples of positive and negative sentiment\ntrain_data = [\n    (\"Helping refugees. This is what kindness looks like.\", {\"cats\": {\"POS\": True}}),\n    (\n        \"In this time of uncertainty, we have a clear way forward: Help Ukraine defend itself. Support the Ukrainian people. Hold Russia accountable.\",\n        {\"cats\": {\"POS\": True}},\n    ),\n    (\n        \"Priests demand head of Ukrainian Orthodox Church Moscow Patriarchate be brought to church tribunal for position on war.\",\n        {\"cats\": {\"POS\": True}},\n    ),\n    (\n        \"Mayor of the most northern village in Ukraine Hremiach Hanna Havrylina was released after yesterday\u2019s prisoners\u2019 swap.\",\n        {\"cats\": {\"POS\": True}},\n    ),\n    (\n        \"Look at this female volunteer from Belarus fighting alongside Ukrainians.\",\n        {\"cats\": {\"POS\": True}},\n    ),\n    (\n        \"Russian soldiers: They're animals... Humans don't behave like this. My parents told me about WW2 & the fascists didn't even do such things.\",\n        {\"cats\": {\"NEG\": True}},\n    ),\n    (\"All Russians are evil\", {\"cats\": {\"NEG\": True}}),\n    (\"The West is pushing Ukraine toward a conflict.\", {\"cats\": {\"NEG\": True}}),\n    (\"Cowards\", {\"cats\": {\"NEG\": True}}),\n    (\n        \"Russia\u2019s deployment of combat forces is a mere repositioning of troops on its own territory.\",\n        {\"cats\": {\"NEG\": True}},\n    ),\n    (\n        \"Ukraine and Ukrainian government officials are the aggressor in the Russia-Ukraine relationship.\",\n        {\"cats\": {\"NEG\": True}},\n    ),\n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0800a4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "textcat.add_label(\"POS\")\ntextcat.add_label(\"NEG\")\n\ntrain_examples = [\n    Example.from_dict(nlp.make_doc(text), label) for text, label in train_data\n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4b9e4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "textcat.initialize(lambda: train_examples, nlp=nlp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4c58c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# Define training example\n\nepochs = 20\n\n# Disable other pipe components & define training loop to incorporate statistical information\n\nwith nlp.select_pipes(enable=\"textcat\"):\n    optimizer = nlp.resume_training()  # Creates optimizer object\n    for i in range(epochs):\n        random.shuffle(train_data)\n        for text, label in train_data:\n            doc = nlp.make_doc(text)\n            example = Example.from_dict(doc, label)\n            print(nlp.update([example], sgd=optimizer))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd3f35",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# enter an example tweet to test results\ndoc2 = nlp(\n    \"As Russia continues to commit horrific atrocities against the Ukrainian people, we must take additional steps to cut off\"\n)\n\nprint(doc2.cats)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a43e2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# enter another example\ndoc3 = nlp(\n    \"One of the captured Russian soldiers who was sent by Putin to \u201cdenazify\u201d Ukraine\"\n)\nprint(doc3.cats)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64144cf3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# process each row in clean text column\ndf[\"nlp_proc\"] = [nlp(i) for i in df[\"clean text\"]]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c352a9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# save positive/negative predictions to cats column\ndf[\"cats\"] = [i.cats for i in df[\"nlp_proc\"]]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38daf1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# assign value of 1 to positive classification, 0 to negative\nsc_val = []\n\nfor i in df[\"cats\"]:\n    if i[\"POS\"] >= 0.5:\n        sc_val.append(1)\n    else:\n        sc_val.append(0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd62bc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# append classification score to dataframe\ndf[\"score\"] = sc_val"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1a3bf",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# check dataframe\ndf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38e976",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# print out tweet id, text and score = to review results\nfor index, i in enumerate(df[\"score\"]):\n    if i == 1:\n        print(df[\"id\"][index], df[\"clean text\"][index], df[\"score\"][index])"
  },
  {
   "cell_type": "markdown",
   "id": "lonely-pacific",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T23:32:10.789097Z",
     "iopub.status.busy": "2021-07-02T23:32:10.788829Z",
     "iopub.status.idle": "2021-07-02T23:32:10.796900Z",
     "shell.execute_reply": "2021-07-02T23:32:10.796358Z",
     "shell.execute_reply.started": "2021-07-02T23:32:10.789033Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-address",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Display wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-poetry",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "# wordcloud\nwordcloud = WordCloud(stopwords=STOPWORDS, collocations=True).generate(str(tokens_list))\n\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "8cdefc1a-81eb-4473-abc2-3364256e291f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Plot positive vs negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1dbfd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "ax = df.score.value_counts().plot(kind=\"bar\", colormap=\"Paired\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "8206ebc2-dbb2-41a4-8e29-df7d8aa02648",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073809c0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "from pathlib import Path\n\noutput_dir = Path(\"spaCy_models\")\n\n\ndef save_model(output_dir):\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n\nsave_model(output_dir)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39013dcc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": "### To load trained, custom model on new data use:\n# nlp = spacy.load(\"spaCy_models\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}