{"cells": [{"cell_type": "markdown", "id": "naas-logo", "metadata": {"papermill": {}, "tags": ["naas"]}, "source": "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"}, {"cell_type": "code", "execution_count": 22, "id": "answering-reach", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:11:04.923993Z", "iopub.status.busy": "2021-05-27T16:11:04.923453Z", "iopub.status.idle": "2021-05-27T16:11:05.654037Z", "shell.execute_reply": "2021-05-27T16:11:05.653334Z", "shell.execute_reply.started": "2021-05-27T16:11:04.923951Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom datetime import date, datetime, timedelta\nimport math\nfrom sktime.utils.plotting import plot_series\nfrom sktime.forecasting.model_selection import (\n    ExpandingWindowSplitter,\n    ForecastingGridSearchCV,\n    SlidingWindowSplitter,\n    temporal_train_test_split,\n)\nfrom sktime.forecasting.arima import ARIMA, AutoARIMA\nfrom sktime.forecasting.compose import (\n    EnsembleForecaster,\n    MultiplexForecaster,\n    TransformedTargetForecaster,\n    make_reduction,\n)\nimport matplotlib.pyplot as plt\nfrom sktime.forecasting.naive import NaiveForecaster\nfrom sktime.forecasting.base import ForecastingHorizon\nfrom sktime.performance_metrics.forecasting import (\n    MeanAbsolutePercentageError,\n    mean_absolute_percentage_error,\n)\nfrom scipy.interpolate import interp1d\nfrom sklearn.neighbors import KNeighborsRegressor\nimport numpy as np\nimport os\nimport sys\nimport tempfile\nimport dateutil.parser\nimport matplotlib.dates as mdates\nimport naas"}, {"cell_type": "code", "execution_count": null, "id": "interracial-presence", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 37, "id": "impaired-melbourne", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:19:48.195397Z", "iopub.status.busy": "2021-05-27T16:19:48.195097Z", "iopub.status.idle": "2021-05-27T16:19:48.241433Z", "shell.execute_reply": "2021-05-27T16:19:48.240717Z", "shell.execute_reply.started": "2021-05-27T16:19:48.195367Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "indicator = SeaLevelIndicator('nasa-sea-level-data.txt')"}, {"cell_type": "code", "execution_count": 13, "id": "pressing-grant", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T15:51:45.032031Z", "iopub.status.busy": "2021-05-27T15:51:45.031786Z", "iopub.status.idle": "2021-05-27T15:51:45.075333Z", "shell.execute_reply": "2021-05-27T15:51:45.074762Z", "shell.execute_reply.started": "2021-05-27T15:51:45.032001Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "'''\nThis is safer to use - it gives a value more inline with current projections, \nbut can be reused with additional data\n'''\nindicator.value(method='curve_fit')"}, {"cell_type": "code", "execution_count": 38, "id": "behavioral-colorado", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:19:49.951440Z", "iopub.status.busy": "2021-05-27T16:19:49.951133Z", "iopub.status.idle": "2021-05-27T16:19:49.984707Z", "shell.execute_reply": "2021-05-27T16:19:49.984160Z", "shell.execute_reply.started": "2021-05-27T16:19:49.951402Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "df = indicator.value_df()"}, {"cell_type": "code", "execution_count": 43, "id": "double-consortium", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:23:54.421310Z", "iopub.status.busy": "2021-05-27T16:23:54.421071Z", "iopub.status.idle": "2021-05-27T16:23:54.585461Z", "shell.execute_reply": "2021-05-27T16:23:54.584814Z", "shell.execute_reply.started": "2021-05-27T16:23:54.421286Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "naas.assets.add('nasa_sealevel_output.csv')"}, {"cell_type": "code", "execution_count": 39, "id": "double-traffic", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:19:50.368881Z", "iopub.status.busy": "2021-05-27T16:19:50.368516Z", "iopub.status.idle": "2021-05-27T16:19:50.373611Z", "shell.execute_reply": "2021-05-27T16:19:50.372779Z", "shell.execute_reply.started": "2021-05-27T16:19:50.368838Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "df.to_csv('data_')"}, {"cell_type": "code", "execution_count": 14, "id": "stock-asthma", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T15:51:47.563496Z", "iopub.status.busy": "2021-05-27T15:51:47.563259Z", "iopub.status.idle": "2021-05-27T15:52:24.071748Z", "shell.execute_reply": "2021-05-27T15:52:24.071129Z", "shell.execute_reply.started": "2021-05-27T15:51:47.563472Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "indicator.value(method='arima')"}, {"cell_type": "code", "execution_count": 15, "id": "athletic-residence", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T15:52:24.073014Z", "iopub.status.busy": "2021-05-27T15:52:24.072813Z", "iopub.status.idle": "2021-05-27T15:52:24.405375Z", "shell.execute_reply": "2021-05-27T15:52:24.404792Z", "shell.execute_reply.started": "2021-05-27T15:52:24.072991Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "indicator.plot_projection(method='curve_fit')"}, {"cell_type": "code", "execution_count": 26, "id": "liable-gospel", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "indicator.plot_projection(method='arima')"}, {"cell_type": "markdown", "id": "responsible-islam", "metadata": {"papermill": {}, "tags": []}, "source": "## Dataset\nSource: Nasa (https://climate.nasa.gov/vital-signs/sea-level/)\nURL: https://podaac-tools.jpl.nasa.gov/drive/files/allData/merged_alt/L2/TP_J1_OSTM/global_mean_sea_level/GMSL_TPJAOS_5.0_199209_202102.txt"}, {"cell_type": "code", "execution_count": 5, "id": "celtic-specification", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T15:50:15.823486Z", "iopub.status.busy": "2021-05-27T15:50:15.823184Z", "iopub.status.idle": "2021-05-27T15:50:15.827324Z", "shell.execute_reply": "2021-05-27T15:50:15.826612Z", "shell.execute_reply.started": "2021-05-27T15:50:15.823454Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "'''\nColumn descriptions\n    1 altimeter type 0=dual-frequency  999=single frequency (ie Poseidon-1) \n    2 merged file cycle # \n    3 year+fraction of year (mid-cycle) \n    4 number of observations \n    5 number of weighted observations \n    6 GMSL (Global Isostatic Adjustment (GIA) not applied) variation (mm) with respect to 20-year \n        TOPEX/Jason collinear mean reference \n    7 standard deviation of GMSL (GIA not applied) variation estimate (mm)\n    8 smoothed (60-day Gaussian type filter) GMSL (GIA not applied) variation (mm)  \n    9 GMSL (Global Isostatic Adjustment (GIA) applied) variation (mm) with respect to 20-year \n        TOPEX/Jason collinear mean reference \n    10 standard deviation of GMSL (GIA applied) variation estimate (mm)\n    11 smoothed (60-day Gaussian type filter) GMSL (GIA applied) variation (mm)\n    12 smoothed (60-day Gaussian type filter) GMSL (GIA applied) variation (mm); \n      annual and semi-annual signal removed\nLearn more @ https://sealevel.colorado.edu/presentation/what-definition-global-mean-sea-level-gmsl-and-its-rate\n'''\npass"}, {"cell_type": "markdown", "id": "advised-holder", "metadata": {"papermill": {}, "tags": []}, "source": "## Code"}, {"cell_type": "code", "execution_count": 36, "id": "worthy-budget", "metadata": {"execution": {"iopub.execute_input": "2021-05-27T16:19:43.986851Z", "iopub.status.busy": "2021-05-27T16:19:43.986623Z", "iopub.status.idle": "2021-05-27T16:19:44.018576Z", "shell.execute_reply": "2021-05-27T16:19:44.017901Z", "shell.execute_reply.started": "2021-05-27T16:19:43.986828Z"}, "papermill": {}, "tags": []}, "outputs": [], "source": "class SeaLevelIndicator():\n    def __init__(self, filepath):\n        self.filepath = filepath\n        self.df = self.get_df()\n        \n        \n    def value_df(self, method='curve_fit'):\n        value = self.value(method)\n        data = {'DATE_PROCESSED': [datetime.today().date()],\n                'INDICATOR': 'Sea Level',\n                 'VALUE': [indicator.value()]}\n        return pd.DataFrame.from_dict(data)\n        \n    def value(self, method='curve_fit'):\n        # interpolate value out of ten\n        m = (10-0)/(self.best_case(value_only=True)-self.worst_case(value_only=True))\n        c = -self.worst_case(value_only=True) * m\n        return m * self.current_projection(method=method, value_only=True) + c\n    \n    def current_projection(self, method='curve_fit', value_only=False):\n        value = None\n        if method.lower() == 'curve_fit':\n            x = mdates.date2num(self.df_per_year['smoothed_GMSL_gia_signal_rem'].index)\n            y = (self.df_per_year['smoothed_GMSL_gia_signal_rem'] \\\n                 + abs(self.df_per_year['smoothed_GMSL_gia_signal_rem'].min())).values\n            z4 = np.polyfit(x, y, 3)\n            p4 = np.poly1d(z4)\n            xx = np.linspace(x.min(), mdates.date2num(datetime(2100, 12, 31)), 100)\n            dd = mdates.num2date(xx)\n            df = pd.DataFrame(data=p4(xx), index=dd) \n            value = df.iloc[-1].values[0]\n        elif method.lower() == 'arima':\n            df = self.df_starting_from_zero.copy()\n            df = df.resample('M').mean()\n            df.index = pd.PeriodIndex(df.index, freq=\"M\")\n            y_train, y_test = temporal_train_test_split(df['smoothed_GMSL_gia_signal_rem'],\n                                                        test_size=180)\n            future_months = (pd.Period('2100-12') - df['smoothed_GMSL_gia_signal_rem'].index[-1]).n\n            forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n            alpha = 0.05  # 95% prediction intervals\n            fh = np.arange(future_months) + 1 # forecast_horizon\n            forecaster.fit(df['smoothed_GMSL_gia_signal_rem'])\n            y_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\n            value = y_pred.iloc[-1]\n        if value_only:\n            return value\n        return {'date': 'December 2100',\n                 'period': '2100-12',\n                 'units': 'Sea Level above 2000 Levels (mm)',\n                 'value': value}\n            \n    def best_case(self, value_only=False):\n        # Source: https://tidesandcurrents.noaa.gov/publications/techrpt83_Global_and_Regional_SLR_Scenarios_for_the_US_final.pdf\n        recorded_value = 300\n        if value_only:\n            return recorded_value\n        return {'date': 'December 2100', 'period': '2100-12', \n                'units': 'Sea Level above 2000 Levels (mm)', 'value': recorded_value}\n    \n    def worst_case(self, value_only=False):\n        # Source: https://tidesandcurrents.noaa.gov/publications/techrpt83_Global_and_Regional_SLR_Scenarios_for_the_US_final.pdf\n        recorded_value = 2500\n        if value_only:\n            return recorded_value\n        return {'date': 'December 2100', 'period': '2100-12', \n                'units': 'Sea Level above 2000 Levels (mm)', 'value': recorded_value}\n    \n    def plot_projection(self, method='curve_fit'):\n        if method.lower() == 'curve_fit':\n            x = mdates.date2num(self.df_per_year['smoothed_GMSL_gia_signal_rem'].index)\n            y = (self.df_per_year['smoothed_GMSL_gia_signal_rem'] \\\n                 + abs(self.df_per_year['smoothed_GMSL_gia_signal_rem'].min())).values\n            z4 = np.polyfit(x, y, 3)\n            p4 = np.poly1d(z4)\n\n            fig, cx = plt.subplots(figsize=(16, 4))\n\n            xx = np.linspace(x.min(), mdates.date2num(datetime(2100, 12, 31)), 100)\n            dd = mdates.num2date(xx)\n\n            cx.plot(dd, p4(xx), '-g')\n            cx.plot(x, y, '+', color='b', label='blub')\n            cx.errorbar(x, y,\n                         marker='.',\n                         color='k',\n                         ecolor='b',\n                         markerfacecolor='b',\n                         label=\"series 1\",\n                         capsize=0,\n                         linestyle='')\n            cx.grid()\n            plt.show()\n            \n        elif method.lower() == 'arima':\n            # Set the frequency of the index, Sktime needs this to work\n            df = self.df_starting_from_zero.copy()\n            df = df.resample('M').mean()\n            df.index = pd.PeriodIndex(df.index, freq=\"M\")\n            y_train, y_test = temporal_train_test_split(df['smoothed_GMSL_gia_signal_rem'],\n                                                        test_size=180)\n            future_months = (pd.Period('2100-12') - df['smoothed_GMSL_gia_signal_rem'].index[-1]).n\n            forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n            alpha = 0.05  # 95% prediction intervals\n            fh = np.arange(future_months) + 1 # forecast_horizon\n            forecaster.fit(df['smoothed_GMSL_gia_signal_rem'])\n            y_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\n            fig, ax = plot_series(df['smoothed_GMSL_gia_signal_rem'], \n                                  y_pred, labels=[\"y_train\", \"y_pred\"])\n            ax.fill_between(\n                ax.get_lines()[-1].get_xdata(),\n                pred_ints[\"lower\"],\n                pred_ints[\"upper\"],\n                alpha=0.2,\n                color=ax.get_lines()[-1].get_c(),\n                label=f\"{1 - alpha}% prediction intervals\",\n            )\n            ax.legend();\n            \n            \n    def get_df(self):\n        cols = ['altimeter_type','merged_file_cycle_#','yearfrac','num_obs','num_w_obs', 'GMSL_variation_mm',\n        'std_GMSL','smoothed_GMSL','GMSL_GIA_variation_mm','std_GMSL_GIA','smoothed_gia_GMSL',\n        'smoothed_GMSL_gia_signal_rem']\n        with open(self.filepath, 'r') as f:\n            data = f.read()\n        data = [d[1:] for d in data.split('\\n') if 'HDR' not in d]\n        df = pd.DataFrame([l.split() for l in data], dtype=float, columns=cols)\n        # Pre-processing        \n        def convert_yearfrac_to_datetime(yearfrac):\n            year = int(yearfrac)\n            rem = yearfrac - year\n            base = datetime(year, 1, 1)\n            return base + timedelta(seconds=(base.replace(year=base.year + 1) - base).total_seconds() * rem)\n        df['datetime'] = df['yearfrac'].apply(lambda year: convert_yearfrac_to_datetime(year))\n        df = df[['datetime', 'smoothed_GMSL_gia_signal_rem']].set_index('datetime')\n        return df\n    \n    def current_value(self, value_only=False):\n        res = requests.get('https://climate.nasa.gov/vital-signs/sea-level/')\n        soup = BeautifulSoup(res.text, 'html.parser')\n        measurement = soup.find_all(\"div\", {\"class\": \"latest_measurement\"})[0]\n        date = measurement.find(\"span\", {\"class\": \"month_year\"}).text.strip()\n        value = measurement.find(\"div\", {\"class\": \"value\"}).text.split('(')[0].strip()\n        if value_only:\n            return value\n        try:\n            period = dateutil.parser.parse(date).strftime('%Y-%m')\n        except:\n            period = None\n        return {'date': date, 'period': period, 'current_value': value}\n    \n    @property\n    def df_starting_from_zero(self):\n        return self.df + abs(self.df.min()) # Here we add the minimum ensure measurements start at zero\n    \n    @property\n    def df_per_year(self):\n        return self.df.resample('Y').mean()\n        \n        "}, {"cell_type": "code", "execution_count": null, "id": "engaged-commissioner", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "# To Do \n# Neaten u notebook\n# Test exponential upon adding datapoint\n# Obtain indicator (based on exponential function)\n# Try make notebook automatically updateable (retrieve data and clean automatically??)\n# Make whatever-obtains-indicator a single function\n# Package everything in a zip file and give to Jeremy"}, {"cell_type": "markdown", "id": "coated-prophet", "metadata": {"papermill": {}, "tags": []}, "source": "# NASA - Indicate sealevel\n<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/NASA/NASA_indicate_sealevel.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/open_in_naas.svg\"/></a>"}, {"cell_type": "markdown", "id": "appropriate-michael", "metadata": {"papermill": {}, "tags": []}, "source": "## Dataset\nSource: Nasa (https://climate.nasa.gov/vital-signs/sea-level/)\nURL: https://podaac-tools.jpl.nasa.gov/drive/files/allData/merged_alt/L2/TP_J1_OSTM/global_mean_sea_level/GMSL_TPJAOS_5.0_199209_202102.txt"}, {"cell_type": "code", "execution_count": 182, "id": "individual-drill", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "## Column descriptions ##\n# 1 altimeter type 0=dual-frequency  999=single frequency (ie Poseidon-1) \n# 2 merged file cycle # \n# 3 year+fraction of year (mid-cycle) \n# 4 number of observations \n# 5 number of weighted observations \n# 6 GMSL (Global Isostatic Adjustment (GIA) not applied) variation (mm) with respect to 20-year \n#   TOPEX/Jason collinear mean reference \n# 7 standard deviation of GMSL (GIA not applied) variation estimate (mm)\n# 8 smoothed (60-day Gaussian type filter) GMSL (GIA not applied) variation (mm)  \n# 9 GMSL (Global Isostatic Adjustment (GIA) applied) variation (mm) with respect to 20-year \n#   TOPEX/Jason collinear mean reference \n# 10 standard deviation of GMSL (GIA applied) variation estimate (mm)\n# 11 smoothed (60-day Gaussian type filter) GMSL (GIA applied) variation (mm)\n# 12 smoothed (60-day Gaussian type filter) GMSL (GIA applied) variation (mm); \n#    annual and semi-annual signal removed\n\n# Learn more @ https://sealevel.colorado.edu/presentation/what-definition-global-mean-sea-level-gmsl-and-its-rate"}, {"cell_type": "markdown", "id": "transparent-dividend", "metadata": {"papermill": {}, "tags": []}, "source": "### 1. Get Current Value of Variable"}, {"cell_type": "code", "execution_count": 712, "id": "innocent-bridal", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "# 1.) Current sea height variation\ndef get_current_value():\n    res = requests.get('https://climate.nasa.gov/vital-signs/sea-level/')\n    soup = BeautifulSoup(res.text, 'html.parser')\n    measurement = soup.find_all(\"div\", {\"class\": \"latest_measurement\"})[0]\n    date = measurement.find(\"span\", {\"class\": \"month_year\"}).text.strip()\n    value = measurement.find(\"div\", {\"class\": \"value\"}).text.split('(')[0].strip()\n    try:\n        period = dateutil.parser.parse(date).strftime('%Y-%m')\n    except:\n        period = None\n    return {'date': date, 'period': period, 'current_value': value}\ncurrent_value = get_current_value()\ncurrent_value"}, {"cell_type": "code", "execution_count": 711, "id": "silver-aside", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "dateutil.parser.parse('January 2021').strftime('%Y-%m')"}, {"cell_type": "code", "execution_count": 699, "id": "entire-balance", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "indicator.df_per_year"}, {"cell_type": "code", "execution_count": 650, "id": "induced-partnership", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "# 2.) Change in mm per year\nres = requests.get('https://climate.nasa.gov')\nsoup = BeautifulSoup(res.text, 'html.parser')\nvital_containers = soup.find_all(\"div\", {\"class\": \"readout\"})\ndef extract_vital(el):\n    vital = {}\n    vital['title'] = el.find(\"div\", {\"class\": \"title\"}).text.strip()\n    vital['units'] = el.find(\"div\", {\"class\": \"units\"}).text.strip()\n    temp = el.find(\"div\", {\"class\": \"change_number\"}).text.strip()\n    if isinstance(temp, str):\n        vital['value'] = float(temp)\n    else:\n        vital['value'] = temp\n    vital['description'] = el.find(\"div\", {\"class\": \"vital_signs_description\"}).text.strip()\n    return vital\nvitals = [extract_vital(el) for el in vital_containers]\ndef specific_vital(title):\n    for vital in vitals:\n        if vital.get('title') == title:\n            return vital\n    return None\ncurrent_change_per_year = specific_vital('Sea Level')['value']\ncurrent_change_per_year"}, {"cell_type": "code", "execution_count": 651, "id": "loaded-weather", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "specific_vital('Sea Level')"}, {"cell_type": "markdown", "id": "compound-antenna", "metadata": {"papermill": {}, "tags": []}, "source": "### 2. Get Current Projection of Variable\n"}, {"cell_type": "code", "execution_count": 417, "id": "favorite-trinity", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "df = pd.read_csv('nasa-wrangled.txt', skiprows=30)\ndf.head(2)"}, {"cell_type": "code", "execution_count": 418, "id": "chemical-presence", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "def convert_yearfrac_to_datetime(yearfrac):\n    year = int(yearfrac)\n    rem = yearfrac - year\n    base = datetime(year, 1, 1)\n    return base + timedelta(seconds=(base.replace(year=base.year + 1) - base).total_seconds() * rem)\ndef sea_level(row):\n    return row[['TOPEX/Poseidon', 'Jason-1', 'Jason-2', 'Jason-3']].mean()\n\ndf['datetime'] = df['yearfrac'].apply(lambda year: convert_yearfrac_to_datetime(year))"}, {"cell_type": "code", "execution_count": 419, "id": "portuguese-force", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "columns = ['datetime', 'smoothed_GMSL_gia_signal_rem']\ndf = df[columns].set_index('datetime')\nsea_height_variation = df + abs(df.min()) # Here we add the minimum ensure measurements start at zero\nsea_height_variation_py = df.resample('Y').mean()\n# df.resample('Y').mean().diff().plot()"}, {"cell_type": "code", "execution_count": null, "id": "angry-december", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 420, "id": "republican-pollution", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "sea_height_variation['smoothed_GMSL_gia_signal_rem'].plot(figsize=(16, 4))"}, {"cell_type": "code", "execution_count": 421, "id": "atmospheric-minutes", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "# Set the frequency of the index, Sktime needs this to work\nsea_height_variation = sea_height_variation.resample('M').mean()\nsea_height_variation.index = pd.PeriodIndex(sea_height_variation.index, freq=\"M\")\ny_train, y_test = temporal_train_test_split(sea_height_variation['smoothed_GMSL_gia_signal_rem'],\n                                            test_size=180)\nplot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\nprint(f'Training dataset size = {y_train.shape[0]} values, test dataset size = {y_test.shape[0]}')"}, {"cell_type": "code", "execution_count": 422, "id": "major-milton", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "fh = np.arange(len(y_test)) + 1"}, {"cell_type": "code", "execution_count": 470, "id": "personal-contrary", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\nalpha = 0.05  # 95% prediction intervals"}, {"cell_type": "code", "execution_count": 471, "id": "reflected-roots", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "forecaster.fit(y_train)\ny_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\nerror = mean_absolute_percentage_error(y_pred, y_test)\nprint(f'The mean absolute error is {error}')"}, {"cell_type": "code", "execution_count": 472, "id": "fantastic-enlargement", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\nax.fill_between(\n    ax.get_lines()[-1].get_xdata(),\n    pred_ints[\"lower\"],\n    pred_ints[\"upper\"],\n    alpha=0.2,\n    color=ax.get_lines()[-1].get_c(),\n    label=f\"{1 - alpha}% prediction intervals\",\n)\nax.legend();"}, {"cell_type": "code", "execution_count": 700, "id": "broke-ireland", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "sea_height_variation"}, {"cell_type": "code", "execution_count": 503, "id": "specialized-disclosure", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "future_months = (pd.Period('2100-12') - sea_height_variation['smoothed_GMSL_gia_signal_rem'].index[-1]).n\nfh = np.arange(future_months) + 1\nforecaster.fit(sea_height_variation['smoothed_GMSL_gia_signal_rem'])\ny_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\nfig, ax = plot_series(sea_height_variation['smoothed_GMSL_gia_signal_rem'], \n                      y_pred, labels=[\"y_train\", \"y_pred\"])\nax.fill_between(\n    ax.get_lines()[-1].get_xdata(),\n    pred_ints[\"lower\"],\n    pred_ints[\"upper\"],\n    alpha=0.2,\n    color=ax.get_lines()[-1].get_c(),\n    label=f\"{1 - alpha}% prediction intervals\",\n)\nax.legend();"}, {"cell_type": "code", "execution_count": 514, "id": "grave-pursuit", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "import scipy\nimport matplotlib.dates as mdates"}, {"cell_type": "code", "execution_count": 602, "id": "partial-exchange", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "x = mdates.date2num(sea_height_variation_py['smoothed_GMSL_gia_signal_rem'].index)\ny = (sea_height_variation_py['smoothed_GMSL_gia_signal_rem'] \\\n     + abs(sea_height_variation_py['smoothed_GMSL_gia_signal_rem'].min())).values\nscipy.optimize.curve_fit(lambda t,a,b: a*np.exp(b*t), x , y)"}, {"cell_type": "code", "execution_count": 600, "id": "contrary-jason", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "# x = np.append(x, 19592)\n# y = np.append(y, 108)"}, {"cell_type": "code", "execution_count": 603, "id": "marked-discretion", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "from matplotlib import pyplot as plt\nz4 = np.polyfit(x, y, 3)\np4 = np.poly1d(z4)\n\nfig, cx = plt.subplots(figsize=(16, 4))\n\nxx = np.linspace(x.min(), mdates.date2num(datetime(2100, 12, 31)), 100)\ndd = mdates.num2date(xx)\n\ncx.plot(dd, p4(xx), '-g')\ncx.plot(x, y, '+', color='b', label='blub')\ncx.errorbar(x, y,\n             marker='.',\n             color='k',\n             ecolor='b',\n             markerfacecolor='b',\n             label=\"series 1\",\n             capsize=0,\n             linestyle='')\n\ncx.grid()\nplt.show()"}, {"cell_type": "code", "execution_count": 591, "id": "refined-platinum", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": "y"}, {"cell_type": "code", "execution_count": null, "id": "average-danger", "metadata": {"papermill": {}, "tags": []}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}, "papermill": {"default_parameters": {}, "environment_variables": {}, "parameters": {}, "version": "2.3.3"}}, "nbformat": 4, "nbformat_minor": 5}