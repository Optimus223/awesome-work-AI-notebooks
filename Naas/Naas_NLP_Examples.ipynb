{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mobile-table",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Naas - NLP Examples\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Naas/Naas_NLP_Example.ipynb\" target=\"_parent\"><img src=\"https://img.shields.io/badge/-Open%20in%20Naas-success?labelColor=000000&logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iMTAyNHB4IiBoZWlnaHQ9IjEwMjRweCIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgdmVyc2lvbj0iMS4xIj4KIDwhLS0gR2VuZXJhdGVkIGJ5IFBpeGVsbWF0b3IgUHJvIDIuMC41IC0tPgogPGRlZnM+CiAgPHRleHQgaWQ9InN0cmluZyIgdHJhbnNmb3JtPSJtYXRyaXgoMS4wIDAuMCAwLjAgMS4wIDIyOC4wIDU0LjUpIiBmb250LWZhbWlseT0iQ29tZm9ydGFhLVJlZ3VsYXIsIENvbWZvcnRhYSIgZm9udC1zaXplPSI4MDAiIHRleHQtZGVjb3JhdGlvbj0ibm9uZSIgZmlsbD0iI2ZmZmZmZiIgeD0iMS4xOTk5OTk5OTk5OTk5ODg2IiB5PSI3MDUuMCI+bjwvdGV4dD4KIDwvZGVmcz4KIDx1c2UgaWQ9Im4iIHhsaW5rOmhyZWY9IiNzdHJpbmciLz4KPC9zdmc+Cg==\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-philip",
   "metadata": {},
   "source": [
    "'#nlp #huggingface #api #models #transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial-tractor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T17:40:38.421664Z",
     "iopub.status.busy": "2021-08-06T17:40:38.421226Z",
     "iopub.status.idle": "2021-08-06T17:40:54.897359Z",
     "shell.execute_reply": "2021-08-06T17:40:54.894543Z",
     "shell.execute_reply.started": "2021-08-06T17:40:38.421563Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas_drivers import nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-arrest",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## How it works?\n",
    "Naas NLP formulas follow this format.\n",
    "```\n",
    "nlp.get(task, model, tokenizer)(inputs)\n",
    "```\n",
    "The supported tasks are the following:\n",
    "\n",
    "- text-generation (model: GPT2)\n",
    "- summarization (model: t5-small)\n",
    "- fill-mask (model: distilroberta-base)\n",
    "- text-classification (model: distilbert-base-uncased-finetuned-sst-2-english)\n",
    "- feature-extraction (model: distilbert-base-cased)\n",
    "- token-classification (model: dslim/bert-base-NER)\n",
    "- question-answering\n",
    "- translation\n",
    "\n",
    "We use [Hugging Face API](https://huggingface.co/models) under the hood to access the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-plaintiff",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broke-ceremony",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T17:40:58.141441Z",
     "iopub.status.busy": "2021-08-06T17:40:58.141133Z",
     "iopub.status.idle": "2021-08-06T17:41:10.912932Z",
     "shell.execute_reply": "2021-08-06T17:41:10.911620Z",
     "shell.execute_reply.started": "2021-08-06T17:40:58.141408Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is the most important thing in your life right now?\\n\\nThe most important thing in my life right now is my body; my mind. How does my body relate to this moment on the physical planet? Because it says what it is.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get(\"text-generation\", model=\"gpt2\", tokenizer=\"gpt2\")(\"What is the most important thing in your life right now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-pharmacology",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "Summarize the text given, maximum lenght (number of tokens/words) is set to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approximate-mexican",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T16:45:26.873833Z",
     "iopub.status.busy": "2021-08-06T16:45:26.873604Z",
     "iopub.status.idle": "2021-08-06T16:45:33.820046Z",
     "shell.execute_reply": "2021-08-06T16:45:33.819350Z",
     "shell.execute_reply.started": "2021-08-06T16:45:26.873810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 183. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'there will be fewer and fewer jobs that a robot cannot do better . what to do about mass unemployment this is gonna be a massive social challenge . we will have to have some kind of universal basic income .'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\")('''\n",
    "\n",
    "There will be fewer and fewer jobs that a robot cannot do better. \n",
    "What to do about mass unemployment this is gonna be a massive social challenge and \n",
    "I think ultimately we will have to have some kind of universal basic income.\n",
    "\n",
    "I think some kind of a universal basic income is going to be necessary \n",
    "now the output of goods and services will be extremely high \n",
    "so with automation they will they will come abundance there will be or almost everything will get very cheap.\n",
    "\n",
    "The harder challenge much harder challenge is how do people then have meaning like a lot of people \n",
    "they find meaning from their employment so if you don't have if you're not needed if \n",
    "there's not a need for your labor how do you what's the meaning if you have meaning \n",
    "if you feel useless these are much that's a much harder problem to deal with. \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-certification",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "Basic sentiment analysis on a text.<br>\n",
    "Returns a \"label\" (negative/neutral/positive), and score between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "detailed-listening",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T16:58:22.576624Z",
     "iopub.status.busy": "2021-08-06T16:58:22.576384Z",
     "iopub.status.idle": "2021-08-06T16:58:26.430114Z",
     "shell.execute_reply": "2021-08-06T16:58:26.429535Z",
     "shell.execute_reply.started": "2021-08-06T16:58:22.576600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.7975085377693176}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get(\"text-classification\", \n",
    "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        tokenizer=\"distilbert-base-uncased-finetuned-sst-2-english\")('''\n",
    "\n",
    "It was a weird concept. Why would I really need to generate a random paragraph? \n",
    "Could I actually learn something from doing so? \n",
    "All these questions were running through her head as she pressed the generate button. \n",
    "To her surprise, she found what she least expected to see.\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-first",
   "metadata": {},
   "source": [
    "## Fill Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-router",
   "metadata": {},
   "source": [
    "Fill the blanks ('< mask >') in a sentence given with multiple proposals. <br>\n",
    "Each proposal has a score (confidence of accuracy), token value (proposed word in number), token_str (proposed word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "toxic-armstrong",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T17:01:21.486795Z",
     "iopub.status.busy": "2021-08-06T17:01:21.486510Z",
     "iopub.status.idle": "2021-08-06T17:01:27.228962Z",
     "shell.execute_reply": "2021-08-06T17:01:27.228305Z",
     "shell.execute_reply.started": "2021-08-06T17:01:21.486767Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '\\n\\nIt was a beautiful sunset.\\n\\n',\n",
       "  'score': 0.09137986600399017,\n",
       "  'token': 18820,\n",
       "  'token_str': ' sunset'},\n",
       " {'sequence': '\\n\\nIt was a beautiful day.\\n\\n',\n",
       "  'score': 0.07021963596343994,\n",
       "  'token': 183,\n",
       "  'token_str': ' day'},\n",
       " {'sequence': '\\n\\nIt was a beautiful sight.\\n\\n',\n",
       "  'score': 0.062469232827425,\n",
       "  'token': 6112,\n",
       "  'token_str': ' sight'},\n",
       " {'sequence': '\\n\\nIt was a beautiful night.\\n\\n',\n",
       "  'score': 0.05541374906897545,\n",
       "  'token': 363,\n",
       "  'token_str': ' night'},\n",
       " {'sequence': '\\n\\nIt was a beautiful evening.\\n\\n',\n",
       "  'score': 0.051386620849370956,\n",
       "  'token': 1559,\n",
       "  'token_str': ' evening'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get(\"fill-mask\",\n",
    "        model=\"distilroberta-base\",\n",
    "        tokenizer=\"distilroberta-base\")('''\n",
    "\n",
    "It was a beautiful <mask>.\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-shoulder",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "This generate a words embedding (extract numbers out of the text data).<br>\n",
    "Output is a list of numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cocktail",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp.get(\"feature-extraction\", model=\"distilbert-base-cased\", tokenizer=\"distilbert-base-cased\")(\"Life is a super cool thing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-george",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "Basically NER. If you give names, location, or any \"entity\" it can detect it.<br>\n",
    "\n",
    "| Entity abreviation | Description                                                                  |\n",
    "|--------------|------------------------------------------------------------------------------|\n",
    "| O            | Outside of a named entity                                                    |\n",
    "| B-MIS        | Beginning of a miscellaneous entity right after another miscellaneous entity |\n",
    "| I-MIS        | Miscellaneous entity                                                         |\n",
    "| B-PER        | Beginning of a person’s name right after another person’s name               |\n",
    "| I-PER        | Person’s name                                                                |\n",
    "| B-ORG        | Beginning of an organization right after another organization                |\n",
    "| I-ORG        | organization                                                                 |\n",
    "| B-LOC        | Beginning of a location right after another location                         |\n",
    "| I-LOC        | Location                                                                     |\n",
    "\n",
    "\n",
    "Full documentation : https://huggingface.co/dslim/bert-base-NER.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deadly-queen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T17:15:52.103220Z",
     "iopub.status.busy": "2021-08-06T17:15:52.102885Z",
     "iopub.status.idle": "2021-08-06T17:15:59.240550Z",
     "shell.execute_reply": "2021-08-06T17:15:59.236068Z",
     "shell.execute_reply.started": "2021-08-06T17:15:52.103186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Wolfgang',\n",
       "  'score': 0.9990139603614807,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 4,\n",
       "  'start': 13,\n",
       "  'end': 21},\n",
       " {'word': 'Berlin',\n",
       "  'score': 0.9996449947357178,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 9,\n",
       "  'start': 36,\n",
       "  'end': 42}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get(\"token-classification\", model=\"dslim/bert-base-NER\", tokenizer=\"dslim/bert-base-NER\")('''\n",
    "\n",
    "My name is Wolfgang and I live in Berlin\n",
    "\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
