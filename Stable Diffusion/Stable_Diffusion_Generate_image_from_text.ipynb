{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faefb65-f69c-494d-8b8c-b74b72f687e5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89373c-f251-4796-b5ea-a246574c53ea",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Stable Diffusion - Generate image from text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133d291-e951-4ea7-9ecf-51f6416a4e87",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #stable-diffusion #image-generation #text-to-image #ai #machine-learning #deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e02164-25a4-4c5c-8789-4bea92046bf5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Oussama El Bahaoui](https://www.linkedin.com/in/oelbahaoui/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e46214-9c5a-49a4-b2d2-b67d39c78755",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook would allow you to generate image from text using Stable Diffusion. It is usefull for organizations to create visuals from text for marketing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b79c1-a7a4-42a6-8e39-9ce02bd3191d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- [Stability.ai - Stable Diffusion](https://stability.ai/stable-diffusion)\n",
    "- [Stability.ai - Text to Image](https://stability.ai/text-to-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe8b29-61d1-4d67-af75-afeb20191533",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef74fc9-5b1d-46e2-a807-0d9ace1d3cb4",
   "metadata": {},
   "source": [
    "### Install and update libraries!pip install --user --upgrade transformers diffusers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e910b4c-ce74-4341-86ca-b2b99625ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade transformers diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e5c84-3ead-4dd5-b8bf-2901e9aa6d89",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f148eb6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T18:40:50.582663Z",
     "iopub.status.busy": "2023-06-04T18:40:50.582353Z",
     "iopub.status.idle": "2023-06-04T18:40:57.089516Z",
     "shell.execute_reply": "2023-06-04T18:40:57.088794Z",
     "shell.execute_reply.started": "2023-06-04T18:40:50.582630Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b873d07-9acd-4a46-88c9-78b64a5e8119",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243cadc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T18:23:39.723079Z",
     "iopub.status.busy": "2023-06-04T18:23:39.722838Z",
     "iopub.status.idle": "2023-06-04T18:23:39.727042Z",
     "shell.execute_reply": "2023-06-04T18:23:39.726112Z",
     "shell.execute_reply.started": "2023-06-04T18:23:39.723055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model to use: this is the identifier for the model repository that we're going to use. \n",
    "# In this case, we're using the \"stable-diffusion-2\" model from the \"stabilityai\" repository.\n",
    "REPO_ID = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "# This is the number of steps the model will take during inference. \n",
    "# In other words, this is the number of times the model will update its predictions.\n",
    "NUM_INFERENCE_STEPS = 25\n",
    "\n",
    "# Image output path\n",
    "IMAGE_PATH = \"output.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287c7e8e-9630-48b0-9ea3-af283641332c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T18:23:39.919628Z",
     "iopub.status.busy": "2023-06-04T18:23:39.919370Z",
     "iopub.status.idle": "2023-06-04T18:23:39.923325Z",
     "shell.execute_reply": "2023-06-04T18:23:39.922364Z",
     "shell.execute_reply.started": "2023-06-04T18:23:39.919603Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt: this is the description that the model will use as a basis to generate the image. \n",
    "\n",
    "prompt = \"A person walking through a field of tall grass\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e6e7b-035a-48c5-94a5-46d6f31da099",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3215937-5c37-4b72-a3b9-dd155dda64a1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Generate image from text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24c449-6df5-46e1-9365-985545617555",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Using Stable Diffusion, we can generate an image from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaacb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-04T18:23:41.694391Z",
     "iopub.status.busy": "2023-06-04T18:23:41.694067Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0792d3a393cf4f94a18a5782cfa4d9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the DiffusionPipeline\n",
    "# This pipeline is created using a pretrained model from the specified repository. \n",
    "# We specify that the model should use 16-bit floating point precision for its computations \n",
    "# (which can help to save memory and improve computational speed, with a slight tradeoff in precision).\n",
    "# We also specify the revision of the model to be \"fp16\".\n",
    "pipe = DiffusionPipeline.from_pretrained(REPO_ID, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "\n",
    "# Modify the scheduler of the pipeline\n",
    "# The scheduler determines the timing of the steps in the diffusion process.\n",
    "# Here, we're creating a new scheduler from the configuration of the current one, which effectively keeps the current scheduler's settings.\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Move the pipeline to GPU\n",
    "# This moves all the computations of the pipeline to the GPU, which is typically much faster than the CPU for these types of tasks.\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e97847-1d33-46f1-a73f-3ae2c1c12674",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf75423-adfc-4fee-8f42-a889bcecdccd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Generate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56688e5b-e92b-4351-bfd5-6576b0fdce70",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate an image from a prompt\n",
    "# This line uses the diffusion pipeline to generate an image from the provided prompt.\n",
    "# The number of inference steps specified is used in the generation process.\n",
    "# The output of the pipeline is a batch of images, and we're taking the first one from this batch.\n",
    "image = pipe(prompt, num_inference_steps=NUM_INFERENCE_STEPS).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf4d7f",
   "metadata": {},
   "source": [
    "### Save and show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image\n",
    "image.save(IMAGE_PATH)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "img = Image.open(IMAGE_PATH)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
