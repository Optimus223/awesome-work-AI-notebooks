{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedfa998",
   "metadata": {
    "id": "G8G4XdnudkS6",
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Hugging Face\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Hugging Face.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff8007-4a9b-425f-a5f1-892655a5de9b",
   "metadata": {
    "id": "cziuXC9hduys",
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Hugging Face - Few Shot Learning with Inference API\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Hugging%20Face/Hugging_Face_Few_Shot_Learning_with_Inference_API.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/Open_in_Naas_Lab.svg\"/></a><br><br><a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Hugging+Face+-+Few+Shot+Learning+with+Inference+API:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776f972",
   "metadata": {
    "id": "CLPRc-MJd982",
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #huggingface #ml #few_shot_learning #prompt #inference_api #ai #text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddb4e8",
   "metadata": {
    "id": "9TxAcynceEXm",
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Saurabh Arjun Sawant](https://www.linkedin.com/in/srsawant34/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2e9ee-568e-43bd-a598-f55404b06ab6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-11-08 (Created: 2023-11-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook demonstrates how to utilize the <a href=\"https://huggingface.co/docs/inference-endpoints/index\">inference endpoints</a> of hugging face models. Additionally, it demonstrates how to use few shot learning for a specific task in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f0816",
   "metadata": {
    "id": "I5qfxShzjrJK",
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b53a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T22:06:30.070094Z",
     "iopub.status.busy": "2022-11-02T22:06:30.069794Z",
     "iopub.status.idle": "2022-11-02T22:06:30.072975Z",
     "shell.execute_reply": "2022-11-02T22:06:30.072331Z",
     "shell.execute_reply.started": "2022-11-02T22:06:30.070062Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d1eac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-08T20:29:52.554694Z",
     "iopub.status.busy": "2023-11-08T20:29:52.554371Z",
     "iopub.status.idle": "2023-11-08T20:30:00.241274Z",
     "shell.execute_reply": "2023-11-08T20:30:00.240562Z",
     "shell.execute_reply.started": "2023-11-08T20:29:52.554658Z"
    },
    "id": "hWQbKgcncvLE",
    "outputId": "218bfc13-27fd-4331-b3c3-304c7986a0b1",
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7133c",
   "metadata": {
    "id": "qGxt0Sy1lQlL",
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f89fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T20:30:00.242902Z",
     "iopub.status.busy": "2023-11-08T20:30:00.242658Z",
     "iopub.status.idle": "2023-11-08T20:30:01.113570Z",
     "shell.execute_reply": "2023-11-08T20:30:01.112970Z",
     "shell.execute_reply.started": "2023-11-08T20:30:00.242869Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3834b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add the Model and API token\n",
    "\n",
    "We will use <a href=\"https://huggingface.co/EleutherAI/gpt-neo-1.3B\">gpt-neo-1.3B</a> model for our demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d02938f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:11:34.006773Z",
     "iopub.status.busy": "2023-11-08T19:11:34.006521Z",
     "iopub.status.idle": "2023-11-08T19:11:34.010795Z",
     "shell.execute_reply": "2023-11-08T19:11:34.010166Z",
     "shell.execute_reply.started": "2023-11-08T19:11:34.006746Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"EleutherAI/gpt-neo-1.3B\"\n",
    "API_TOKEN = \"<INSERT_API_TOKEN>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec280229",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e868fc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Define function to make API calls to Hugging Face endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c02550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:47:21.815058Z",
     "iopub.status.busy": "2023-11-08T18:47:21.814813Z",
     "iopub.status.idle": "2023-11-08T18:47:21.821996Z",
     "shell.execute_reply": "2023-11-08T18:47:21.821243Z",
     "shell.execute_reply.started": "2023-11-08T18:47:21.815034Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query(\n",
    "        payload='', \n",
    "        model = 'EleutherAI/gpt-neo-1.3B', \n",
    "        parameters = {\n",
    "            'max_new_tokens':5,\n",
    "            'temperature': 0.5\n",
    "        }, \n",
    "        options = {\n",
    "            'use_cache': False\n",
    "        }\n",
    "    ):\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    body = {\"inputs\":payload,'parameters':parameters,'options':options}\n",
    "    \n",
    "    try:\n",
    "        response = requests.request(\"POST\", API_URL, headers=headers, data= json.dumps(body))\n",
    "        return response.json()[0]['generated_text']\n",
    "    except:\n",
    "        return \"Error: \" + \" \".join(response.json()['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378de1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T22:04:21.973105Z",
     "iopub.status.busy": "2022-11-02T22:04:21.972816Z",
     "iopub.status.idle": "2022-11-02T22:04:21.980111Z",
     "shell.execute_reply": "2022-11-02T22:04:21.977454Z",
     "shell.execute_reply.started": "2022-11-02T22:04:21.973076Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0724801-389c-4184-b3a1-a3491573e24e",
   "metadata": {},
   "source": [
    " The model usually takes time to load in the hugging face server. For example, model gpt-neo-1.3B takes approximately 212 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0a8f9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc20e20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-08T18:51:14.968874Z",
     "iopub.status.busy": "2023-11-08T18:51:14.968639Z",
     "iopub.status.idle": "2023-11-08T18:51:16.537316Z",
     "shell.execute_reply": "2023-11-08T18:51:16.536640Z",
     "shell.execute_reply.started": "2023-11-08T18:51:14.968851Z"
    },
    "id": "9yETPBqgoWpO",
    "outputId": "062820d9-a750-45ea-b263-ec617df962d6",
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: I loved todays movie.\n",
      "Sentiment: \n",
      "\n",
      "A:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24f731",
   "metadata": {
    "id": "zaufheoZo4mf",
    "papermill": {},
    "tags": []
   },
   "source": [
    "### One-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e3ccf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:52:00.192577Z",
     "iopub.status.busy": "2023-11-08T18:52:00.192341Z",
     "iopub.status.idle": "2023-11-08T18:52:01.729565Z",
     "shell.execute_reply": "2023-11-08T18:52:01.728932Z",
     "shell.execute_reply.started": "2023-11-08T18:52:00.192552Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: I loved todays movie.\n",
      "Sentiment: positive\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: I didn't like the action.\n",
      "Sentiment:  negative\n",
      "\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: positive\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: I didn't like the action.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96831b89-e92f-4ddb-8703-0124c26c8613",
   "metadata": {},
   "source": [
    "### Two-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "166b6be0-c30a-4f70-93c4-b993558e741f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:52:51.711071Z",
     "iopub.status.busy": "2023-11-08T18:52:51.710766Z",
     "iopub.status.idle": "2023-11-08T18:52:53.495876Z",
     "shell.execute_reply": "2023-11-08T18:52:53.495096Z",
     "shell.execute_reply.started": "2023-11-08T18:52:51.711037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: I loved todays movie.\n",
      "Sentiment: positive\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: I didn't like the action.\n",
      "Sentiment: negative\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: Liked the direction and scene settings.\n",
      "Sentiment:  positive\n",
      "\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: positive\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: I didn't like the action.\n",
    "Sentiment: negative\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: Liked the direction and scene settings.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89831a-ccd8-4e78-b140-f69a94c6af12",
   "metadata": {},
   "source": [
    "### Few-shot learning with custom dataset\n",
    "\n",
    "You can also use any custom dataset and generate prompts like above. For example, below we will use <a href=\"https://huggingface.co/datasets/carblacac/twitter-sentiment-analysis\">twitter-sentiment-analysis</a>. More datasets in huggingface can be found <a href=\"https://huggingface.co/datasets\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835a322b-3967-42f3-a77d-720d1308a998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T20:30:17.284487Z",
     "iopub.status.busy": "2023-11-08T20:30:17.284259Z",
     "iopub.status.idle": "2023-11-08T20:30:18.444948Z",
     "shell.execute_reply": "2023-11-08T20:30:18.444377Z",
     "shell.execute_reply.started": "2023-11-08T20:30:17.284463Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_with_examples(data, target_col, num_of_examples = 0):\n",
    "    examples = np.random.choice(data, num_of_examples + 1)\n",
    "    prompts = []\n",
    "    for example in examples:\n",
    "        review = example[\"text\"]\n",
    "        sentiment = \"positive\" if example[target_col] else \"negative\"\n",
    "        prompt = f\"Sentence: {review}\\nSentiment: {sentiment}\\n\"\n",
    "        prompts.append(prompt)\n",
    "    return \"\"\"\\n#####\\n\\n\"\"\".join(prompts)[:-9]\n",
    "\n",
    "data = load_dataset('carblacac/twitter-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4156dc7-b4ce-482b-91bc-759097782b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:58:08.522236Z",
     "iopub.status.busy": "2023-11-08T18:58:08.521989Z",
     "iopub.status.idle": "2023-11-08T18:58:11.522555Z",
     "shell.execute_reply": "2023-11-08T18:58:11.521823Z",
     "shell.execute_reply.started": "2023-11-08T18:58:08.522211Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: wow! I have so much homework for tomorrow!\n",
      "Sentiment: negative\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: @thepete I know. I hate that/those shows. (Actually there's one I do get addicted to - X-Factor) But I hate it too!\n",
      "Sentiment: positive\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: @cakesandbakes Ohh nooo!  We're in America! Lol spoilt little brat aren't I?\n",
      "Sentiment: \n"
     ]
    }
   ],
   "source": [
    "prompt = generate_prompt_with_examples(data=data['train'], target_col=\"feeling\", num_of_examples=2)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e80171-fb45-495f-99fa-dbb801cec7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:58:35.364455Z",
     "iopub.status.busy": "2023-11-08T18:58:35.364202Z",
     "iopub.status.idle": "2023-11-08T18:58:37.323862Z",
     "shell.execute_reply": "2023-11-08T18:58:37.323135Z",
     "shell.execute_reply.started": "2023-11-08T18:58:35.364427Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: wow! I have so much homework for tomorrow!\n",
      "Sentiment: negative\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: @thepete I know. I hate that/those shows. (Actually there's one I do get addicted to - X-Factor) But I hate it too!\n",
      "Sentiment: positive\n",
      "\n",
      "#####\n",
      "\n",
      "Sentence: @cakesandbakes Ohh nooo!  We're in America! Lol spoilt little brat aren't I?\n",
      "Sentiment:  positive\n",
      "\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce2e67-fa35-4986-9dc0-55bbf1726ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "6ae02ceb527a779c1815a5254e6a3b1292f024034c61fa1c62c4dfcb88905990",
   "notebook_path": "Hugging Face/Hugging_Face_Question_Answering_from_PDF.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
